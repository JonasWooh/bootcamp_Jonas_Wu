{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Starter — Stage 15: Orchestration & System Design\n",
    "Complete the sections below. Keep your answers concise and focused on orchestration readiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Project Task Decomposition\n",
    "List 4–8 tasks. Add more rows as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>inputs</th>\n",
       "      <th>outputs</th>\n",
       "      <th>idempotent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ingest_data</td>\n",
       "      <td>raw_data_source_url</td>\n",
       "      <td>data/raw/raw_data.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validate_data</td>\n",
       "      <td>data/raw/raw_data.csv</td>\n",
       "      <td>reports/validation_report.json</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean_data</td>\n",
       "      <td>data/raw/raw_data.csv</td>\n",
       "      <td>data/processed/cleaned_data.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_engineering</td>\n",
       "      <td>data/processed/cleaned_data.csv</td>\n",
       "      <td>data/features/features.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_model</td>\n",
       "      <td>data/features/features.csv</td>\n",
       "      <td>model/model.pkl</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>evaluate_model</td>\n",
       "      <td>(model/model.pkl, data/features/features.csv)</td>\n",
       "      <td>reports/evaluation_metrics.json</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>generate_report</td>\n",
       "      <td>reports/evaluation_metrics.json</td>\n",
       "      <td>reports/final_report.md</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  task                                         inputs  \\\n",
       "0          ingest_data                            raw_data_source_url   \n",
       "1        validate_data                          data/raw/raw_data.csv   \n",
       "2           clean_data                          data/raw/raw_data.csv   \n",
       "3  feature_engineering                data/processed/cleaned_data.csv   \n",
       "4          train_model                     data/features/features.csv   \n",
       "5       evaluate_model  (model/model.pkl, data/features/features.csv)   \n",
       "6      generate_report                reports/evaluation_metrics.json   \n",
       "\n",
       "                           outputs  idempotent  \n",
       "0            data/raw/raw_data.csv        True  \n",
       "1   reports/validation_report.json        True  \n",
       "2  data/processed/cleaned_data.csv        True  \n",
       "3       data/features/features.csv        True  \n",
       "4                  model/model.pkl       False  \n",
       "5  reports/evaluation_metrics.json        True  \n",
       "6          reports/final_report.md        True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tasks = pd.DataFrame([\n",
    "    {'task': 'ingest_data', 'inputs': 'raw_data_source_url', 'outputs': 'data/raw/raw_data.csv', 'idempotent': True},\n",
    "    {'task': 'validate_data', 'inputs': 'data/raw/raw_data.csv', 'outputs': 'reports/validation_report.json', 'idempotent': True},\n",
    "    {'task': 'clean_data', 'inputs': 'data/raw/raw_data.csv', 'outputs': 'data/processed/cleaned_data.csv', 'idempotent': True},\n",
    "    {'task': 'feature_engineering', 'inputs': 'data/processed/cleaned_data.csv', 'outputs': 'data/features/features.csv', 'idempotent': True},\n",
    "    {'task': 'train_model', 'inputs': 'data/features/features.csv', 'outputs': 'model/model.pkl', 'idempotent': False},\n",
    "    {'task': 'evaluate_model', 'inputs': ('model/model.pkl', 'data/features/features.csv'), 'outputs': 'reports/evaluation_metrics.json', 'idempotent': True},\n",
    "    {'task': 'generate_report', 'inputs': 'reports/evaluation_metrics.json', 'outputs': 'reports/final_report.md', 'idempotent': True}\n",
    "])\n",
    "\n",
    "tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dependencies (DAG)\n",
    "Describe dependencies and paste a small diagram if you have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ingest_data': [],\n",
       " 'validate_data': ['ingest_data'],\n",
       " 'clean_data': ['ingest_data'],\n",
       " 'feature_engineering': ['clean_data'],\n",
       " 'train_model': ['feature_engineering'],\n",
       " 'evaluate_model': ['train_model', 'feature_engineering'],\n",
       " 'generate_report': ['evaluate_model']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag = {\n",
    "    'ingest_data': [],\n",
    "    'validate_data': ['ingest_data'],\n",
    "    'clean_data': ['ingest_data'],\n",
    "    'feature_engineering': ['clean_data'],\n",
    "    'train_model': ['feature_engineering'],\n",
    "    'evaluate_model': ['train_model', 'feature_engineering'],\n",
    "    'generate_report': ['evaluate_model']\n",
    "}\n",
    "dag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be7071",
   "metadata": {},
   "source": [
    "The dependency graph is mostly linear, but some tasks could be run in parallel.\n",
    "\n",
    "**DAG Flow:**\n",
    "\n",
    "`ingest_data` -> `validate_data` & `clean_data` (These two can run in parallel after ingestion).\n",
    "\n",
    "`clean_data` -> `feature_engineering`\n",
    "\n",
    "`feature_engineering` -> `train_model`\n",
    "\n",
    "(`train_model`, `feature_engineering`) -> `evaluate_model`\n",
    "\n",
    "`evaluate_model` -> `generate_report`\n",
    "\n",
    "**Visual Sketch:**\n",
    "\n",
    "[ingest] --> [validate]\n",
    "\n",
    "|\n",
    "\n",
    "+------> [clean] --> [features] --> [train] --> [evaluate] --> [report]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Logging & Checkpoints Plan\n",
    "Specify what you will log and where you will checkpoint for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>log_messages</th>\n",
       "      <th>checkpoint_artifact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ingest_data</td>\n",
       "      <td>Start/end time, source URL, number of records ...</td>\n",
       "      <td>data/raw/raw_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validate_data</td>\n",
       "      <td>Start/end time, validation status (pass/fail),...</td>\n",
       "      <td>reports/validation_report.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean_data</td>\n",
       "      <td>Start/end time, input/output row count, number...</td>\n",
       "      <td>data/processed/cleaned_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_engineering</td>\n",
       "      <td>Start/end time, list of features created, outp...</td>\n",
       "      <td>data/features/features.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_model</td>\n",
       "      <td>Start/end time, model parameters, training dur...</td>\n",
       "      <td>model/model.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>evaluate_model</td>\n",
       "      <td>Start/end time, evaluation metrics (MAE, R2), ...</td>\n",
       "      <td>reports/evaluation_metrics.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>generate_report</td>\n",
       "      <td>Start/end time, path to generated report file.</td>\n",
       "      <td>reports/final_report.md</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  task                                       log_messages  \\\n",
       "0          ingest_data  Start/end time, source URL, number of records ...   \n",
       "1        validate_data  Start/end time, validation status (pass/fail),...   \n",
       "2           clean_data  Start/end time, input/output row count, number...   \n",
       "3  feature_engineering  Start/end time, list of features created, outp...   \n",
       "4          train_model  Start/end time, model parameters, training dur...   \n",
       "5       evaluate_model  Start/end time, evaluation metrics (MAE, R2), ...   \n",
       "6      generate_report     Start/end time, path to generated report file.   \n",
       "\n",
       "               checkpoint_artifact  \n",
       "0            data/raw/raw_data.csv  \n",
       "1   reports/validation_report.json  \n",
       "2  data/processed/cleaned_data.csv  \n",
       "3       data/features/features.csv  \n",
       "4                  model/model.pkl  \n",
       "5  reports/evaluation_metrics.json  \n",
       "6          reports/final_report.md  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging_plan = pd.DataFrame([\n",
    "    {'task': 'ingest_data', 'log_messages': 'Start/end time, source URL, number of records ingested.', 'checkpoint_artifact': 'data/raw/raw_data.csv'},\n",
    "    {'task': 'validate_data', 'log_messages': 'Start/end time, validation status (pass/fail), list of validation errors.', 'checkpoint_artifact': 'reports/validation_report.json'},\n",
    "    {'task': 'clean_data', 'log_messages': 'Start/end time, input/output row count, number of nulls handled.', 'checkpoint_artifact': 'data/processed/cleaned_data.csv'},\n",
    "    {'task': 'feature_engineering', 'log_messages': 'Start/end time, list of features created, output data shape.', 'checkpoint_artifact': 'data/features/features.csv'},\n",
    "    {'task': 'train_model', 'log_messages': 'Start/end time, model parameters, training duration, final training score.', 'checkpoint_artifact': 'model/model.pkl'},\n",
    "    {'task': 'evaluate_model', 'log_messages': 'Start/end time, evaluation metrics (MAE, R2), metric thresholds passed/failed.', 'checkpoint_artifact': 'reports/evaluation_metrics.json'},\n",
    "    {'task': 'generate_report', 'log_messages': 'Start/end time, path to generated report file.', 'checkpoint_artifact': 'reports/final_report.md'}\n",
    "])\n",
    "logging_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Right-Sizing Automation\n",
    "Which parts will you automate now? Which stay manual? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the current project phase, our automation strategy focuses on balancing efficiency with the need for human oversight.\n",
    "\n",
    "**What to Automate Now:**\n",
    "We will automate the core data processing and model training pipeline, from `ingest_data` through `evaluate_model`. These tasks are deterministic, repetitive, and form the backbone of our workflow. Automating them ensures consistency, reduces manual error, and allows the data science team to focus on analysis rather than execution. We can schedule this pipeline to run on a weekly basis to retrain the model with fresh data.\n",
    "\n",
    "**What to Keep Manual (For Now):**\n",
    "The final `generate_report` task and the subsequent decision to deploy the newly trained model into production will remain manual. The evaluation metrics from the `evaluate_model` step will be automatically generated, but a data scientist must review them to provide context and interpretation. This human-in-the-loop step is critical to catch subtle model degradations or anomalies that automated thresholds might miss. Model deployment should only occur after this manual sign-off to mitigate business risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) (Stretch) Refactor One Task into a Function + CLI\n",
    "Use the templates below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Simulating CLI call ---\n",
      "2025-08-28 02:12:03,209 - INFO - [clean_data] start: Cleaning data from data/raw/dummy_raw.csv\n",
      "2025-08-28 02:12:03,216 - INFO - [clean_data] completed. Rows before: 4, rows after: 2.\n",
      "2025-08-28 02:12:03,217 - INFO - [clean_data] wrote cleaned data to data/processed/dummy_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def clean_data(input_path: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Reads raw data from input_path, performs simple cleaning, \n",
    "    and saves the result to output_path.\n",
    "    \n",
    "    Cleaning logic: Drops rows with any missing values.\n",
    "    \"\"\"\n",
    "    logging.info(f'[clean_data] start: Cleaning data from {input_path}')\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_path)\n",
    "        rows_before = len(df)\n",
    "        \n",
    "        # Simple cleaning: drop rows with nulls\n",
    "        df_cleaned = df.dropna()\n",
    "        rows_after = len(df_cleaned)\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        df_cleaned.to_csv(output_path, index=False)\n",
    "        \n",
    "        logging.info(f'[clean_data] completed. Rows before: {rows_before}, rows after: {rows_after}.')\n",
    "        logging.info(f'[clean_data] wrote cleaned data to {output_path}')\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"[clean_data] error: Input file not found at {input_path}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[clean_data] an unexpected error occurred: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def main(argv=None):\n",
    "    \"\"\"Parses command line arguments and runs the clean_data task.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Data cleaning task wrapper')\n",
    "    parser.add_argument('--input', required=True, help='Path to the raw input CSV file.')\n",
    "    parser.add_argument('--output', required=True, help='Path to save the cleaned output CSV file.')\n",
    "    args = parser.parse_args(argv)\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.StreamHandler(sys.stdout)])\n",
    "    \n",
    "    clean_data(args.input, args.output)\n",
    "\n",
    "# To demonstrate, let's create a dummy input file first.\n",
    "# In a real scenario, this would already exist from the 'ingest' step.\n",
    "Path('data/raw').mkdir(parents=True, exist_ok=True)\n",
    "dummy_df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, 7, 8]})\n",
    "dummy_df.to_csv('data/raw/dummy_raw.csv', index=False)\n",
    "\n",
    "# Example of simulating the CLI call within the notebook:\n",
    "print(\"--- Simulating CLI call ---\")\n",
    "main(['--input', 'data/raw/dummy_raw.csv', '--output', 'data/processed/dummy_cleaned.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Simple Retry Wrapper (fill in)\n",
    "Add a small retry with linear backoff to harden a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing retry wrapper (should succeed on 3rd try):\n",
      "2025-08-28 02:12:11,868 - WARNING - Attempt 1/3 failed for sometimes_fail_task. Retrying in 0.5s... Error: Simulating failure on attempt 1\n",
      "2025-08-28 02:12:12,374 - WARNING - Attempt 2/3 failed for sometimes_fail_task. Retrying in 0.5s... Error: Simulating failure on attempt 2\n",
      "Succeeded on attempt 3!\n",
      "\n",
      "Testing retry wrapper (should fail all 3 times):\n",
      "2025-08-28 02:12:12,877 - WARNING - Attempt 1/3 failed for sometimes_fail_task. Retrying in 0.5s... Error: Simulating failure on attempt 1\n",
      "2025-08-28 02:12:13,382 - WARNING - Attempt 2/3 failed for sometimes_fail_task. Retrying in 0.5s... Error: Simulating failure on attempt 2\n",
      "2025-08-28 02:12:13,888 - ERROR - All 3 attempts failed for sometimes_fail_task. Error: Simulating failure on attempt 3\n",
      "Caught expected exception after all retries: Simulating failure on attempt 3\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import logging\n",
    "\n",
    "def retry(n_tries=3, delay_s=1):\n",
    "    \"\"\"\n",
    "    A simple decorator to retry a function if it fails.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            attempts = 0\n",
    "            while attempts < n_tries:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    attempts += 1\n",
    "                    if attempts < n_tries:\n",
    "                        logging.warning(f\"Attempt {attempts}/{n_tries} failed for {func.__name__}. Retrying in {delay_s}s... Error: {e}\")\n",
    "                        time.sleep(delay_s)\n",
    "                    else:\n",
    "                        logging.error(f\"All {n_tries} attempts failed for {func.__name__}. Error: {e}\")\n",
    "                        raise  # Re-raise the last exception\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# --- Example Usage ---\n",
    "@retry(n_tries=3, delay_s=0.5)\n",
    "def sometimes_fail_task(attempt_to_succeed):\n",
    "    \"\"\"\n",
    "    A dummy function that fails until a certain attempt number.\n",
    "    \"\"\"\n",
    "    global attempt_counter\n",
    "    attempt_counter += 1\n",
    "    if attempt_counter < attempt_to_succeed:\n",
    "        raise ValueError(f\"Simulating failure on attempt {attempt_counter}\")\n",
    "    else:\n",
    "        print(f\"Succeeded on attempt {attempt_counter}!\")\n",
    "        return \"Success\"\n",
    "\n",
    "# Test the retry wrapper\n",
    "attempt_counter = 0\n",
    "print(\"Testing retry wrapper (should succeed on 3rd try):\")\n",
    "sometimes_fail_task(attempt_to_succeed=3)\n",
    "\n",
    "attempt_counter = 0\n",
    "print(\"\\nTesting retry wrapper (should fail all 3 times):\")\n",
    "try:\n",
    "    sometimes_fail_task(attempt_to_succeed=4)\n",
    "except ValueError as e:\n",
    "    print(f\"Caught expected exception after all retries: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
