{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 16 Homework Starter\n",
    "\n",
    "This notebook is a starting point for polishing your final repo and lifecycle mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklist Template\n",
    " - Add checklist elements, as in the examples below, to make sure you cover everything you would like to accomplish\n",
    "- Update this checklist as you finalize your repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repo_clean': False,\n",
       " 'repo_complete': False,\n",
       " 'readme_complete': False,\n",
       " 'lifecycle_map': False,\n",
       " 'summary_doc': False,\n",
       " 'framework_guide_table': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checklist = {\n",
    "    \"repo_clean\": False,\n",
    "    \"repo_complete\": False,\n",
    "    \"readme_complete\": False,\n",
    "    \"lifecycle_map\": False,\n",
    "    \"summary_doc\": False,\n",
    "    \"framework_guide_table\": False,\n",
    "}\n",
    "checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Repo Checklist\n",
    "\n",
    "- [ ] **1. Clean Folder Structure**: Verify that the repository contains the following clean folder structure:\n",
    "  - `/data` (with subfolders like `/raw`, `/processed`)\n",
    "  - `/notebooks` (containing cleaned, final versions of notebooks)\n",
    "  - `/src` (containing all `.py` script files)\n",
    "  - `/model` (containing the final `model.pkl`)\n",
    "  - `/reports` (containing the stakeholder summary and this framework guide)\n",
    "\n",
    "- [ ] **2. Complete `README.md`**: Ensure the main `README.md` file is complete. It should include:\n",
    "  - Project overview and goals.\n",
    "  - Instructions on how to set up the environment (`pip install -r requirements.txt`).\n",
    "  - How to run the key parts of the project (e.g., notebooks, API).\n",
    "  - A summary of the project's lifecycle mapping.\n",
    "\n",
    "- [ ] **3. `requirements.txt` is Present**: A `requirements.txt` file exists in the root directory and contains all necessary libraries with their versions.\n",
    "\n",
    "- [ ] **4. Stakeholder Summary Document**: A stakeholder-friendly summary document (PDF, slide deck, or Markdown file) is included in the `/reports` directory. This is the deliverable from Stage 12.\n",
    "\n",
    "- [ ] **5. Framework Guide is Complete**: The `framework_guide_table.md` file (which you just filled out) is complete and saved in the `/reports` directory.\n",
    "\n",
    "- [ ] **6. Finalize and Push Commits**: All final changes have been committed to GitHub with clear, descriptive commit messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Prompts\n",
    "- What stage of the lifecycle was hardest for you, and why?\n",
    "- Which part of your repo is most reusable in a future project?\n",
    "- If a teammate had to pick up your repo tomorrow, what would help them most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Which stage was the most difficult for you, and why?** Stage 14 (Deployment & Monitoring) was the most difficult. It required a shift in mindset from just building a model that is \"accurate\" to thinking about all the real-world failure points of a live system, such as data pipeline delays, API latency, and concept drift. Defining specific, measurable thresholds for alerts was challenging without real-world operational data.\n",
    "\n",
    "- **Which stage was the most rewarding?** Stage 13 (Productization) was the most rewarding. Seeing the trained model, which was previously just an object in a notebook, come to life as a functional REST API that could be called from anywhere was a very tangible and exciting outcome. It felt like the bridge between data science and a real product.\n",
    "\n",
    "- **How do the stages connect — where did one stage’s decisions constrain or enable later stages?** The stages are deeply connected. For example, the decision in Stage 6 (Preprocessing) to handle nulls by simply dropping rows was fast, but it could cause the `train_model` task in Stage 10 to fail if a future data ingest (Stage 4) contains too many nulls. Conversely, the decision in Stage 15 (Orchestration) to break the project into small, checkpointed tasks enabled more robust error handling and easier debugging during the monitoring design in Stage 14.\n",
    "\n",
    "- **If you repeated this project, what would you do differently across the lifecycle?** I would adopt a \"production-first\" mindset from the beginning. I would start by sketching the orchestration DAG (Stage 15) and the monitoring dashboard (Stage 14) right after scoping the problem (Stage 1). This would force me to write modular, testable, and log-ready code from the start, making the final productization and deployment stages much smoother.\n",
    "\n",
    "- **Which skills do you most want to strengthen before your next financial engineering project?** I want to strengthen my skills in MLOps and system design. Specifically, I'd like to gain hands-on experience with Docker for containerization and a proper workflow orchestration tool like Prefect or Airflow. This would allow me to build more robust, scalable, and maintainable end-to-end systems.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
